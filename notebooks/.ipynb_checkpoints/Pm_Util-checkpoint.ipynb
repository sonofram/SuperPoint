{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# proj_home_path=\"C:/vrsk.psk.family/Selva/BitsPilani/azure/semester4/semester4/SuperPoint\"\n",
    "# sys.path.append(proj_home_path)\n",
    "\n",
    "# from superpoint.settings import EXPER_PATH\n",
    "\n",
    "\n",
    "def _read_image(filename):\n",
    "    image = tf.read_file(filename)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    return tf.cast(image, tf.float32)\n",
    "\n",
    "# Python function\n",
    "def _read_points(filename):\n",
    "    return np.load(filename.decode('utf-8')).astype(np.float32)\n",
    "\n",
    "def draw_keypoints(img, corners, color):\n",
    "    keypoints = [cv2.KeyPoint(c[1], c[0], 1) for c in corners]\n",
    "    return cv2.drawKeypoints(img.astype(np.uint8), keypoints, None, color=color)\n",
    "def display(d):\n",
    "    return draw_keypoints(d['image'], d['keypoints'], (0, 255, 0))\n",
    "\n",
    "def getDataIter(shape_dir_list,num_images_per_shape,data_dir, img_dir,p_dir):\n",
    "    '''\n",
    "        shape_dir_list : directory name that holds specific type of shapes\n",
    "        num_images_per_shape: number of images randomly picked from the shapes directory\n",
    "        data_dir: base directory for both images and corner points\n",
    "        idir: full directory path for specifc shape generation\n",
    "        pdir: full directory path for specifc corner points generation\n",
    "    '''\n",
    "    #================= LIST RANDOM FILES =============================\n",
    "    ifiles =  []\n",
    "    pfiles = []\n",
    " \n",
    "    # Randomly pick num_images_per_shape count of images\n",
    "    for sdir in shape_dir_list:\n",
    "        idir = data_dir+sdir+img_dir\n",
    "        pdir = data_dir+sdir+p_dir\n",
    "        ifiles_list = [f for f in os.listdir(idir)]\n",
    "        random_ifiles = np.random.choice(ifiles_list, num_images_per_shape)\n",
    "        random_pfiles = [ f.replace(\".png\",\".npy\") for f in random_ifiles]\n",
    "        random_ifiles = [os.path.join(idir, f) for f in random_ifiles]\n",
    "        random_pfiles = [os.path.join(pdir, f) for f in random_pfiles]\n",
    "            \n",
    "        # Accumulate images in list for later operations.\n",
    "        if ifiles == None:\n",
    "            ifiles = random_ifiles\n",
    "            pfiles = random_pfiles\n",
    "        else:    \n",
    "            ifiles = ifiles + random_ifiles\n",
    "            pfiles = pfiles + random_pfiles\n",
    "\n",
    "    #================ READ LISTED FILES ===========================\n",
    "    data = tf.data.Dataset.from_tensor_slices(\n",
    "            (ifiles, pfiles))\n",
    "    data = data.map(\n",
    "            lambda image, points:\n",
    "            (_read_image(image), tf.py_func(_read_points, [points], tf.float32)))\n",
    "    data = data.map(lambda image, points: (image, tf.reshape(points, [-1, 2])))\n",
    "    data = data.map(lambda image, kp: {'image': image, 'keypoints': kp})\n",
    "    tf_next = data.make_one_shot_iterator().get_next()\n",
    "    sess = tf.Session()\n",
    "    while True:\n",
    "        yield sess.run(tf_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
